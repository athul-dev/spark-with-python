{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data\n",
      "+---------------------+-----+\n",
      "|reviews              |label|\n",
      "+---------------------+-----+\n",
      "|It was just wonderful|1    |\n",
      "|not so good          |0    |\n",
      "|very very negative   |0    |\n",
      "|super super duper    |1    |\n",
      "|average quality      |0    |\n",
      "+---------------------+-----+\n",
      "\n",
      "Tokenizer Output - Splitting text on Whitespaces\n",
      "+---------------------+-----+--------------------------+\n",
      "|reviews              |label|review_tokens             |\n",
      "+---------------------+-----+--------------------------+\n",
      "|It was just wonderful|1    |[it, was, just, wonderful]|\n",
      "|not so good          |0    |[not, so, good]           |\n",
      "|very very negative   |0    |[very, very, negative]    |\n",
      "|super super duper    |1    |[super, super, duper]     |\n",
      "|average quality      |0    |[average, quality]        |\n",
      "+---------------------+-----+--------------------------+\n",
      "\n",
      "HashingTF Data\n",
      "+--------------------------+----------------------------------------+\n",
      "|             review_tokens|                                 hashVec|\n",
      "+--------------------------+----------------------------------------+\n",
      "|[it, was, just, wonderful]|(262144,[25570,71225,86175,97171],[1....|\n",
      "|           [not, so, good]|(262144,[113432,139098,188424],[1.0,1...|\n",
      "|    [very, very, negative]|      (262144,[210040,251061],[2.0,1.0])|\n",
      "|     [super, super, duper]|       (262144,[80042,226659],[1.0,2.0])|\n",
      "|        [average, quality]|        (262144,[1846,250865],[1.0,1.0])|\n",
      "+--------------------------+----------------------------------------+\n",
      "\n",
      "Final Spark accepted Data - NLP Formatted Data ready to pass into any Machine Learning Model\n",
      "+-----+------------------------------------------------------------+\n",
      "|label|                                                    features|\n",
      "+-----+------------------------------------------------------------+\n",
      "|    1|(262144,[25570,71225,86175,97171],[1.0986122886681098,1.0...|\n",
      "|    0|(262144,[113432,139098,188424],[1.0986122886681098,1.0986...|\n",
      "|    0|(262144,[210040,251061],[2.1972245773362196,1.09861228866...|\n",
      "|    1|(262144,[80042,226659],[1.0986122886681098,2.197224577336...|\n",
      "|    0|(262144,[1846,250865],[1.0986122886681098,1.0986122886681...|\n",
      "+-----+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Code Snippet 37\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('TF-IDF_HashTF').getOrCreate()\n",
    "from pyspark.ml.feature import Tokenizer,HashingTF,IDF\n",
    "data = spark.read.csv('reviews_tf-idf.csv',header=True,inferSchema=True)\n",
    "print(\"Initial Data\")\n",
    "data.show(truncate=False)\n",
    "#Applying Tokenizer class which splits text on whitespaces\n",
    "simple_tokenizer = Tokenizer(inputCol='reviews',outputCol='review_tokens')\n",
    "simple_tokens = simple_tokenizer.transform(data)\n",
    "print(\"Tokenizer Output - Splitting text on Whitespaces\")\n",
    "simple_tokens.show(truncate=False)\n",
    "#Applying HashingTF\n",
    "hashingtf_vectors = HashingTF(inputCol='review_tokens',outputCol='hashVec')\n",
    "HashingTF_featurized_data = hashingtf_vectors.transform(simple_tokens)\n",
    "print(\"HashingTF Data\")\n",
    "HashingTF_featurized_data.select('review_tokens','hashVec').show(truncate=40)\n",
    "#Applying IDF on vectors of token count output from HashingTF\n",
    "idf = IDF(inputCol='hashVec',outputCol='features')\n",
    "idf_model = idf.fit(HashingTF_featurized_data)\n",
    "final_data = idf_model.transform(HashingTF_featurized_data)\n",
    "print(\"Final Spark accepted Data - NLP Formatted Data ready to pass into any Machine Learning Model\")\n",
    "final_data.select('label','features').show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
