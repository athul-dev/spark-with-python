{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data\n",
      "+---------------------+-----+\n",
      "|reviews              |label|\n",
      "+---------------------+-----+\n",
      "|It was just wonderful|1    |\n",
      "|not so good          |0    |\n",
      "|very very negative   |0    |\n",
      "|super super duper    |1    |\n",
      "|average quality      |0    |\n",
      "+---------------------+-----+\n",
      "\n",
      "Tokenizer Output - Splitting text on Whitespaces\n",
      "+---------------------+-----+--------------------------+\n",
      "|reviews              |label|review_tokens             |\n",
      "+---------------------+-----+--------------------------+\n",
      "|It was just wonderful|1    |[it, was, just, wonderful]|\n",
      "|not so good          |0    |[not, so, good]           |\n",
      "|very very negative   |0    |[very, very, negative]    |\n",
      "|super super duper    |1    |[super, super, duper]     |\n",
      "|average quality      |0    |[average, quality]        |\n",
      "+---------------------+-----+--------------------------+\n",
      "\n",
      "CountVectorizer Data\n",
      "+--------------------------+---------------------------------+\n",
      "|review_tokens             |countVec                         |\n",
      "+--------------------------+---------------------------------+\n",
      "|[it, was, just, wonderful]|(13,[3,4,8,10],[1.0,1.0,1.0,1.0])|\n",
      "|[not, so, good]           |(13,[2,7,9],[1.0,1.0,1.0])       |\n",
      "|[very, very, negative]    |(13,[1,6],[2.0,1.0])             |\n",
      "|[super, super, duper]     |(13,[0,11],[2.0,1.0])            |\n",
      "|[average, quality]        |(13,[5,12],[1.0,1.0])            |\n",
      "+--------------------------+---------------------------------+\n",
      "\n",
      "Final Spark accepted Data - NLP Formatted Data ready to pass into any Machine Learning Model\n",
      "+-----+------------------------------------------------------------+\n",
      "|label|                                                    features|\n",
      "+-----+------------------------------------------------------------+\n",
      "|    1|(13,[3,4,8,10],[1.0986122886681098,1.0986122886681098,1.0...|\n",
      "|    0|(13,[2,7,9],[1.0986122886681098,1.0986122886681098,1.0986...|\n",
      "|    0|          (13,[1,6],[2.1972245773362196,1.0986122886681098])|\n",
      "|    1|         (13,[0,11],[2.1972245773362196,1.0986122886681098])|\n",
      "|    0|         (13,[5,12],[1.0986122886681098,1.0986122886681098])|\n",
      "+-----+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Code Snippet 38\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('TF-IDF_CountVec').getOrCreate()\n",
    "from pyspark.ml.feature import Tokenizer,CountVectorizer,IDF\n",
    "data = spark.read.csv('reviews_tf-idf.csv',header=True,inferSchema=True)\n",
    "print(\"Initial Data\")\n",
    "data.show(truncate=False)\n",
    "#Applying Tokenizer class which splits text on whitespaces\n",
    "simple_tokenizer = Tokenizer(inputCol='reviews',outputCol='review_tokens')\n",
    "simple_tokens = simple_tokenizer.transform(data)\n",
    "print(\"Tokenizer Output - Splitting text on Whitespaces\")\n",
    "simple_tokens.show(truncate=False)\n",
    "#Applying CountVectorizer and HashingTF to convert tokens to vectors of token count\n",
    "#Applying CountVectorizer\n",
    "count_vectors = CountVectorizer(inputCol='review_tokens',outputCol='countVec')\n",
    "count_vectors_model = count_vectors.fit(simple_tokens)\n",
    "countVector_featurized_data = count_vectors_model.transform(simple_tokens)\n",
    "print(\"CountVectorizer Data\")\n",
    "countVector_featurized_data.select('review_tokens','countVec').show(truncate=False)\n",
    "#Applying IDF on vectors of token count output from CountVectorizer\n",
    "idf = IDF(inputCol='countVec',outputCol='features')\n",
    "idf_model = idf.fit(countVector_featurized_data)\n",
    "final_data = idf_model.transform(countVector_featurized_data)\n",
    "print(\"Final Spark accepted Data - NLP Formatted Data ready to pass into any Machine Learning Model\")\n",
    "final_data.select('label','features').show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
